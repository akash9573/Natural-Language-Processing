import nltk
from nltk.stem import WordNetLemmatizer, PorterStemmer
from nltk.tokenize import word_tokenize
from nltk.corpus import wordnet

# Download required NLTK resources
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')

# Initialize lemmatizer and stemmer
lemmatizer = WordNetLemmatizer()
stemmer = PorterStemmer()

# Sample text
text = "The runners are running faster than ever before."

# Tokenize the text
tokens = word_tokenize(text)

# Perform lemmatization
print("Lemmatization:")
for token in tokens:
    lemmatized_word = lemmatizer.lemmatize(token)
    print(f"Original: {token}, Lemmatized: {lemmatized_word}")

# Perform stemming
print("\nStemming:")
for token in tokens:
    stemmed_word = stemmer.stem(token)
    print(f"Original: {token}, Stemmed: {stemmed_word}")

# Example of getting part of speech for lemmatization
def get_wordnet_pos(treebank_tag):
    if treebank_tag.startswith('J'):
        return wordnet.ADJ
    elif treebank_tag.startswith('V'):
        return wordnet.VERB
    elif treebank_tag.startswith('N'):
        return wordnet.NOUN
    elif treebank_tag.startswith('R'):
        return wordnet.ADV
    else:
        return wordnet.NOUN

# POS tagging
tagged_tokens = nltk.pos_tag(tokens)

print("\nLemmatization with POS Tagging:")
for token, tag in tagged_tokens:
    wordnet_pos = get_wordnet_pos(tag)
    lemmatized_word = lemmatizer.lemmatize(token, pos=wordnet_pos)
    print(f"Original: {token}, Lemmatized: {lemmatized_word}, POS: {tag}")
